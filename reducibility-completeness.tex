\subsection{Reducibility and Completeness}

As we have seen in the previous section, it is currently unknown whether \(\textsf{P} = \textsf{NP}\). As far as we know, it could be as easy to decide a problem with a deterministic machine as it is to decide it with a nondeterministic one. We don't know if problems in \textsf{NP} are \emph{strictly harder} thans those in \textsf{P} (even though we suspect them to be). This is hardly surprising given the vastness of \textsf{NP}. In order to prove \(\textsf{P} = \textsf{NP}\), one must find a polynomial time algorithm for \emph{every} problem in \textsf{NP}. And in order to prove that \(\textsf{P} \neq \textsf{NP}\), one must prove that for at least one problem in \textsf{NP}, \emph{all algorithms} are not polynomial time (this is admittedly an easier task than proving equality).

The point above is valid for all pairs of classes for which we have one inclusion but are uncertain of the other (\textsf{NP} and \textsf{EXPTIME} for example). The notion of completeness simplifies the task of proving inequality of two classes by reducing it to the task of proving that \emph{one particular} problem (intuitively thought of as the hardest problem) in the supposedly bigger class is in deed a member of the smaller one. These \emph{most difficult problems} are what the concept of completeness aims to formalize. In order to define them, we must first address the question of how to compare the difficulty of two problems, which is exactly what the relation of \emph{reducibility} introduced in Definition~\ref{def:polynomial-reduction} allows us to do.

\newcommand{\ple}{\preceq_\textsf{P}}
\begin{definition}[Polynomial Reduction]\ \\
    \label{def:polynomial-reduction}
    Let \(X = \langle S_1, P_1\rangle\) and \(Y =\langle S_2, P_2\rangle\) be two decision problems. A \emph{polynomial reduction} of \(X\) to \(Y\) is a function \(f:S_1 \rightarrow S_2\) computable by a deterministic Turing machine in polynomial time such that:
    \[\forall i \in S_1\ i \in P_1 \iff f(i) \in P_2\]
    If such a reduction exists, \(X\) is said to be \emph{polynomially reducible} to \(Y\), which we denote by \(X \ple Y\).
\end{definition}

One can show that \(\ple\) is both transitive, and reflexive (a quasi-order on decision problems) without too much difficulty. Furthermore, the relation \(ple\) can be shown to satisfy Proposition~\ref{prop:ple-p-p} which will become very importent once \textsf{NP}-completeness is defined.
\begin{proposition}\ \\
    \label{prop:ple-p-p}
    Let \(X = \langle S_1, P_1\rangle\) and \(Y =\langle S_2, P_2\rangle\) be two decision problems. If \(X \ple Y\) and \(Y \in \textsf{P}\), then \(X \in \textsf{P}\).
\end{proposition}
\begin{proof}\ \\
    The composition of the Turing machine that computes the polynomial reduction of \(X\) to \(Y\) and the one that decides \(Y\) in polynomial time is a polynomial time Turing machine that decides \(X\).
\end{proof}

We are now ready to define the notion of \textsf{NP}-completeness.
\begin{definition}[\textsf{NP}-hardness, \textsf{NP}-completeness]\ \\
    A problem \(X\) is \textsf{NP}-hard if and only if :
    \[\forall Y \in \textsf{NP}\ Y \ple X\]
    A problem \(X\) is \textsf{NP}-complete if and only if \(X\) is \textsf{NP}-hard and \(X\in\textsf{NP}\).
\end{definition}

Under our intuitive interpretation of \(\ple\), an \textsf{NP}-hard problem is a problem that is at least as difficult as any problem in \textsf{NP}. An \textsf{NP}-complete one is then the hardest problem in \textsf{NP}. It stands to reason then that if an \textsf{NP}-hard problem \(X\) is in \textsf{P}, we would have \(\textsf{NP} \subset \textsf{P}\) and hence \(\textsf{P}= \textsf{NP}\). This is in deed the case as affirmed by Corollary~\ref{cor:p=np}.

\begin{corollary}
    \label{cor:p=np}
    If \(\textsf{P} \cap \textsf{NP}\mathrm{-hard} \neq \emptyset\), then \(\textsf{P}=\textsf{NP}\)
\end{corollary}

\begin{proof}\ \\
    Let \(X\) be an \textsf{NP}-hard problem that is also in \textsf{P}, and let \(Y\in\textsf{NP}\). By definition of \textsf{NP}-hardness, \(Y\ple X\), and by Proposition~\ref{prop:ple-p-p} and the fact that \(X\in\textsf{P}\), \(Y\in\textsf{P}\).
    Therefore, \(\textsf{NP} \subset \textsf{P}\), and hence \(\textsf{P}=\textsf{NP}\).
\end{proof}

Although the idea of \textsf{NP}-completeness is promising, it is not immediately obvious how it makes approaching \textsf{P} vs \textsf{NP} easier. It would seem that proving a problem is \textsf{NP}-hard is as difficult as solving \textsf{P} vs \textsf{NP}. This is once more due to the unfathomable vastness of \textsf{NP}. Fortunately, this initial impression proved to be a false one, since we know of many \textsf{NP}-hard and \textsf{NP}-complete problems. The first problem proved to be \textsf{NP}-complete is the problem \textsf{SAT} that we invoked in Example~\ref{ex:sat}, and that was proven to be \textsf{NP}-complete in 1971.

\begin{theorem}[Cook Levin]\ \\
    \textsf{SAT} is \textsf{NP}-complete.
\end{theorem}

\begin{proof}\ \\
    The proof is twofold. First, we know that \(\textsf{SAT} \in \textsf{NP}\), and second, that it is \textsf{NP}-hard. The first part is more or less trivial, the second by comparaison is very technical. It requires finding a polynomial reduction of every single problem in \textsf{NP} to \textsf{SAT}.

    \begin{enumerate}
        \item \underline{\(\textsf{SAT} \in \textsf{NP}\):}
        
    \end{enumerate}
\end{proof}