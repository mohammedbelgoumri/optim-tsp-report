\subsection{Reducibility and Completeness}

As we have seen in the previous section, it is currently unknown whether \(\textsf{P} = \textsf{NP}\). As far as we know, it could be as easy to decide a problem with a deterministic machine as it is to decide it with a nondeterministic one. We don't know if problems in \textsf{NP} are \emph{strictly harder} than those in \textsf{P} (even though we suspect them to be). This is hardly surprising given the vastness of \textsf{NP}. In order to prove \(\textsf{P} = \textsf{NP}\), one must find a polynomial time algorithm for \emph{every} problem in \textsf{NP}. And in order to prove that \(\textsf{P} \neq \textsf{NP}\), one must prove that for at least one problem in \textsf{NP}, \emph{all algorithms} are not polynomial time (this is admittedly an easier task than proving equality).

The point above is valid for all pairs of classes for which we have one inclusion but are uncertain of the other (\textsf{NP} and \textsf{EXPTIME} for example). The notion of completeness simplifies the task of proving inequality of two classes by reducing it to the task of proving that \emph{one particular} problem (intuitively thought of as the hardest problem) in the supposedly bigger class is in deed a member of the smaller one. These \emph{most difficult problems} are what the concept of completeness aims to formalize. In order to define them, we must first address the question of how to compare the difficulty of two problems, which is exactly what the relation of \emph{reducibility} introduced in Definition~\ref{def:polynomial-reduction} allows us to do.

\newcommand{\ple}{\preceq_\textsf{P}}
\begin{definition}[Polynomial Reduction]\ \\
    \label{def:polynomial-reduction}
    Let \(X = \langle S_1, P_1\rangle\) and \(Y =\langle S_2, P_2\rangle\) be two decision problems. A \emph{polynomial reduction} of \(X\) to \(Y\) is a function \(f:S_1 \rightarrow S_2\) computable by a deterministic Turing machine in polynomial time such that:
    \[\forall i \in S_1\ i \in P_1 \iff f(i) \in P_2\]
    If such a reduction exists, \(X\) is said to be \emph{polynomially reducible} to \(Y\), which we denote by \(X \ple Y\).
\end{definition}

One can show that \(\ple\) is both transitive, and reflexive (a preorder on decision problems) without too much difficulty. Furthermore, the relation \(\ple\) can be shown to satisfy Proposition~\ref{prop:ple-p-p} which will become very important once \textsf{NP}-completeness is defined.
\begin{proposition}\ \\
    \label{prop:ple-p-p}
    Let \(X \) and \(Y \) be two decision problems. If \(X \ple Y\) and \(Y \in \textsf{P}\), then \(X \in \textsf{P}\).
\end{proposition}
\begin{proof}\ \\
    The composition of the Turing machine that computes the polynomial reduction of \(X\) to \(Y\) and the one that decides \(Y\) in polynomial time is a polynomial time Turing machine that decides \(X\).
\end{proof}

We now define \textsf{NP}-completeness.
\begin{definition}[\textsf{NP}-hardness, \textsf{NP}-completeness]\ \\
    A problem \(X\) is \textsf{NP}-hard if and only if :
    \[\forall Y \in \textsf{NP}\ Y \ple X\]
    A problem \(X\) is \textsf{NP}-complete if and only if \(X\) is \textsf{NP}-hard and \(X\in\textsf{NP}\).
\end{definition}

Under our intuitive interpretation of \(\ple\), an \textsf{NP}-hard problem is a problem that is at least as difficult as any problem in \textsf{NP}. An \textsf{NP}-complete one is then the hardest problem in \textsf{NP}. It stands to reason then that if an \textsf{NP}-hard problem \(X\) is in \textsf{P}, we would have \(\textsf{NP} \subset \textsf{P}\) and hence \(\textsf{P}= \textsf{NP}\). This is in deed the case as affirmed by Corollary~\ref{cor:p=np}.

\begin{corollary}
    \label{cor:p=np}
    If \(\textsf{P} \cap \textsf{NP}\mathrm{-hard} \neq \emptyset\), then \(\textsf{P}=\textsf{NP}\)
\end{corollary}

\begin{proof}\ \\
    Let \(X\) be an \textsf{NP}-hard problem that is also in \textsf{P}, and let \(Y\in\textsf{NP}\). By definition of \textsf{NP}-hardness, \(Y\ple X\), and by Proposition~\ref{prop:ple-p-p} and the fact that \(X\in\textsf{P}\), \(Y\in\textsf{P}\).
    Therefore, \(\textsf{NP} \subset \textsf{P}\), and hence \(\textsf{P}=\textsf{NP}\).
\end{proof}

The same intuitive analysis that led us to Corollary~\ref{cor:p=np} suggests that if a problem is harder\footnote{In the \(\ple\) sense.} than an \textsf{NP}-hard problem, then it must be \textsf{NP}-hard as well. This is once again correct as affirmed by Proposition~\ref{prop:ple-nph}.

\begin{proposition}\ \\
    \label{prop:ple-nph}
    Let \(X\) and \(Y\) be two decision problems. If \(X\) is \textsf{NP}-hard and \(X\ple Y\), then \(Y\) is \textsf{NP}-hard.
\end{proposition}

\begin{proof}\ \\
    Let \(X, Y, Z\) be decision problems such that \(X\) is \textsf{NP}-hard and \(X\ple Y\), and \(Z \in\textsf{NP}\). By  \textsf{NP}-hardness of \(X\), \(Z \ple X\), and by transitivity of \(\ple\) we have \(Z \ple Y\). \(Y\) is then \textsf{NP}-hard.
\end{proof}

Although the idea of \textsf{NP}-completeness is promising, it is not immediately obvious how it makes approaching \textsf{P} vs \textsf{NP} easier. It would seem that proving a problem is \textsf{NP}-hard is as difficult as solving \textsf{P} vs \textsf{NP}. This is once more due to the unfathomable vastness of \textsf{NP}. Fortunately, this initial impression proved wrong. We know of many \textsf{NP}-hard and \textsf{NP}-complete problems. The first problem to be proven \textsf{NP}-complete is the problem \textsf{SAT} we invoked in Example~\ref{ex:sat}. This has been done by Stephen Cook and Leonid Levin who proved Theorem~\ref{thm:cook-levin} in 1971. A proof of this theorem is given in~\cite{langages-formels}.

\begin{theorem}[Cook Levin]\ \\
    \label{thm:cook-levin}
    \textsf{SAT} is \textsf{NP}-complete.
\end{theorem}

Now that we have one problem that we know is \textsf{NP}-complete, it becomes significantly easier to prove that a given problem is \textsf{NP}-hard. Using Proposition~\ref{prop:ple-nph}, we can show any problem is \textsf{NP}-hard by reducing a known \textsf{NP}-hard problem to it. This is what we will do in the following example by proving 3-\textsf{SAT} is \textsf{NP}-complete.

\begin{example}\ \\
    \label{ex:3sat-npc}
    An instance of 3-\textsf{SAT} is a conjunction of clauses with at most 3 literals each and is positive iff it is satisfiable. To show that 3-\textsf{SAT} is \textsf{NP}-complete, we will reduce \textsf{SAT} to it. It is technically necessary to show that \(3\textsf{-SAT}\in\textsf{NP}\) too, but this is easy given that it is a subproblem of \textsf{SAT} which is already known to be in \textsf{NP}. We will therefore focus on proving it \textsf{NP}-hard.

    To reduce \textsf{SAT} to 3-\textsf{SAT}, we must find for every formula \(\varphi\) of boolean logic a formula \(\varphi^\prime\) in 3CNF, with size polynomial in that of \(\varphi\), such that \(\varphi^\prime\) is satisfiable iff \(\varphi\) is satisfiable. We start by considering the \emph{syntax tree} of \(\varphi\), for example, the syntax tree of the formula 
    \[\varphi = \left((x_1 \vee \neg x_2) \wedge x_3\right) \vee (x_2 \wedge \neg x_3)\] 
    is shown in Figure~\ref{fig:3sat-npc-syntax-tree}. We label each internal node of this tree with a new variable (the leaves are associated with the variables of \(\varphi\)), we get the tree of Figure~\ref{fig:3sat-npc-var-tree}.

    Each new variable \(x_i\) is then associated with an equivalence \(e_i\) according to the following rules:
    \begin{itemize}
        \item If the node labeled by the variable \(x_i\) is \(\vee\), we associate it with the formula \(x_i \leftrightarrow x_j \vee x_k\) where \(x_j\) and \(x_k\) are the children of \(x_i\).
        \item If it is labeled with \(\wedge\), we associate it with the formula \(x_i \leftrightarrow x_j \wedge x_k\).
        \item If it is labeled with \(\neg\), we associate with the formula \(x_i \leftrightarrow \neg x_j\).
    \end{itemize}

    Finally, by taking the conjunction\footnote{\(n\) being the number of variables in \(\varphi\)} 
    \(\bigwedge\limits_{i>n}e_i\) of the equivalences thus obtained, and replacing equivalences with their clausal forms given by the following tautologies:
    \[
        \begin{array}{rcl}
            x \leftrightarrow \neg y &\equiv& (x\vee\neg y)\wedge (\neg x \vee y) \\
            x \leftrightarrow y \wedge z &\equiv& (x\vee\neg y\vee\neg z) \wedge 
            (\neg x \wedge y) \wedge (\neg x \wedge z) \\
            x \leftrightarrow y \wedge z &\equiv& (\neg x\vee y\vee z) \wedge 
            (x \wedge\neg y) \wedge (x \wedge\neg z) \\
        \end{array}
    \]

    We get a formula \(\varphi^\prime\) in 3CNF, which is logically equivalent to\(\varphi\) (and is a fortiori satisfiable iff \(\varphi\) is satisfiable). Furthermore, since the size of the syntax tree is proportional to the size of \(\varphi\), so is the size of \(\varphi^\prime\) (i.e. this reduction is in deed polynomial). It then follows that
    \(\textsf{SAT} \ple 3\textsf{-SAT}\), and by Proposition~\ref{prop:ple-nph}, that 3-\textsf{SAT} is \textsf{NP}-complete.
    \begin{figure}
        \begin{center}
            \begin{tikzpicture}[level 1/.style={sibling distance=30mm},level 2/.style={sibling distance=15mm}]
                \node {\(\vee\)}
                child{
                    node {\(\wedge\)}
                    child{
                        node {\(\vee\)}
                        child {node {\(x_1\)}}
                        child {
                            node {\(\neg\)}
                            child {node {\(x_2\)}}
                        }
                    }
                    child {node {\(x_3\)}}
                }
                child {
                    node {\(\wedge\)}
                    child {node {\(x_2\)}}
                    child {
                        node {\(\neg\)}
                        child {node {\(x_3\)}}
                    }
                };
            \end{tikzpicture}
        \end{center}
        \caption{Syntax tree of the formula \(\varphi\)}
        \label{fig:3sat-npc-syntax-tree}
    \end{figure}

    \begin{figure}
        \begin{center}
            \begin{tikzpicture}[level 1/.style={sibling distance=30mm},level 2/.style={sibling distance=15mm}]
                \node {\(x_4\)}
                child{
                    node {\(x_5\)}
                    child{
                        node {\(x_6\)}
                        child {node {\(x_1\)}}
                        child {
                            node {\(x_7\)}
                            child {node {\(x_2\)}}
                        }
                    }
                    child {node {\(x_3\)}}
                }
                child {
                    node {\(x_8\)}
                    child {node {\(x_2\)}}
                    child {
                        node {\(x_9\)}
                        child {node {\(x_3\)}}
                    }
                };
            \end{tikzpicture}
        \end{center}
        \caption{Syntax tree of Figure~\ref{fig:3sat-npc-syntax-tree} labeled with new variables.}
        \label{fig:3sat-npc-var-tree}
    \end{figure}
\end{example}

Using similar techniques, countless problems have been shown to be \textsf{NP}-complete. Examples include \textsf{CLIQUE} (the problem of deciding whether a graph has a \(k\)-clique for \(k\in\naturals\)),  \textsf{VERTEX-COVER} (the problem of deciding whether a graph has a covering set of vertices with cardinality \(k\) for \(k\in\naturals\)), and crucially for our study, \textsf{HAM} (mentioned in Example~\ref{ex:decision-problems}).

