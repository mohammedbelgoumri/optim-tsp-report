\subsection{Reducibility and Completeness}

As we have seen in the previous section, it is currently unknown whether \(\textsf{P} = \textsf{NP}\). As far as we know, it could be as easy to decide a problem with a deterministic machine as it is to decide it with a nondeterministic one. We don't know if problems in \textsf{NP} are \emph{strictly harder} thans those in \textsf{P} (even though we suspect them to be). This is hardly surprising given the vastness of \textsf{NP}. In order to prove \(\textsf{P} = \textsf{NP}\), one must find a polynomial time algorithm for \emph{every} problem in \textsf{NP}. And in order to prove that \(\textsf{P} \neq \textsf{NP}\), one must prove that for at least one problem in \textsf{NP}, \emph{all algorithms} are not polynomial time (this is admittedly an easier task than proving equality).

The point above is valid for all pairs of classes for which we have one inclusion but are uncertain of the other (\textsf{NP} and \textsf{EXPTIME} for example). The notion of completeness simplifies the task of proving inequality of two classes by reducing it to the task of proving that \emph{one particular} problem (intuitively thought of as the hardest problem) in the supposedly bigger class is in deed a member of the smaller one. These \emph{most difficult problems} are what the concept of completeness aims to formalize. In order to define them, we must first address the question of how to compare the difficulty of two problems, which is exactly what the relation of \emph{reducibility} introduced in Definition~\ref{def:polynomial-reduction} allows us to do.

\newcommand{\ple}{\preceq_\textsf{P}}
\begin{definition}[Polynomial Reduction]\ \\
    \label{def:polynomial-reduction}
    Let \(X = \langle S_1, P_1\rangle\) and \(Y =\langle S_2, P_2\rangle\) be two decision problems. A \emph{polynomial reduction} of \(X\) to \(Y\) is a function \(f:S_1 \rightarrow S_2\) computable by a deterministic Turing machine in polynomial time such that:
    \[\forall i \in S_1\ i \in P_1 \iff f(i) \in P_2\]
    If such a reduction exists, \(X\) is said to be \emph{polynomially reducible} to \(Y\), which we denote by \(X \ple Y\).
\end{definition}

One can show that \(\ple\) is both transitive, and reflexive (a quasi-order on decision problems) without too much difficulty. Furthermore, the relation \(\ple\) can be shown to satisfy Proposition~\ref{prop:ple-p-p} which will become very importent once \textsf{NP}-completeness is defined.
\begin{proposition}\ \\
    \label{prop:ple-p-p}
    Let \(X \) and \(Y \) be two decision problems. If \(X \ple Y\) and \(Y \in \textsf{P}\), then \(X \in \textsf{P}\).
\end{proposition}
\begin{proof}\ \\
    The composition of the Turing machine that computes the polynomial reduction of \(X\) to \(Y\) and the one that decides \(Y\) in polynomial time is a polynomial time Turing machine that decides \(X\).
\end{proof}

We now define \textsf{NP}-completeness.
\begin{definition}[\textsf{NP}-hardness, \textsf{NP}-completeness]\ \\
    A problem \(X\) is \textsf{NP}-hard if and only if :
    \[\forall Y \in \textsf{NP}\ Y \ple X\]
    A problem \(X\) is \textsf{NP}-complete if and only if \(X\) is \textsf{NP}-hard and \(X\in\textsf{NP}\).
\end{definition}

Under our intuitive interpretation of \(\ple\), an \textsf{NP}-hard problem is a problem that is at least as difficult as any problem in \textsf{NP}. An \textsf{NP}-complete one is then the hardest problem in \textsf{NP}. It stands to reason then that if an \textsf{NP}-hard problem \(X\) is in \textsf{P}, we would have \(\textsf{NP} \subset \textsf{P}\) and hence \(\textsf{P}= \textsf{NP}\). This is in deed the case as affirmed by Corollary~\ref{cor:p=np}.

\begin{corollary}
    \label{cor:p=np}
    If \(\textsf{P} \cap \textsf{NP}\mathrm{-hard} \neq \emptyset\), then \(\textsf{P}=\textsf{NP}\)
\end{corollary}

\begin{proof}\ \\
    Let \(X\) be an \textsf{NP}-hard problem that is also in \textsf{P}, and let \(Y\in\textsf{NP}\). By definition of \textsf{NP}-hardness, \(Y\ple X\), and by Proposition~\ref{prop:ple-p-p} and the fact that \(X\in\textsf{P}\), \(Y\in\textsf{P}\).
    Therefore, \(\textsf{NP} \subset \textsf{P}\), and hence \(\textsf{P}=\textsf{NP}\).
\end{proof}

The same intuitive analysis that led us to Corollary~\ref{cor:p=np} suggests that if a problem is harder\footnote{In the \(\ple\) sence.} than an \textsf{NP}-hard problem, then it must be \textsf{NP}-hard as well. This is once again correct as affirmed by Proposition~\ref{prop:ple-nph}.

\begin{proposition}\ \\
    \label{prop:ple-nph}
    Let \(X\) and \(Y\) be two decision problems. If \(X\) is \textsf{NP}-hard and \(X\ple Y\), then \(Y\) is \textsf{NP}-hard.
\end{proposition}

\begin{proof}\ \\
    Let \(X, Y, Z\) be decision problems such that \(X\) is \textsf{NP}-hard and \(X\ple Y\), and \(Z \in\textsf{NP}\). By  \textsf{NP}-hardness of \(X\), \(Z \ple X\), and by transitivity of \(\ple\) we have \(Z \ple Y\). \(Y\) is then \textsf{NP}-hard.
\end{proof}

Although the idea of \textsf{NP}-completeness is promising, it is not immediately obvious how it makes approaching \textsf{P} vs \textsf{NP} easier. It would seem that proving a problem is \textsf{NP}-hard is as difficult as solving \textsf{P} vs \textsf{NP}. This is once more due to the unfathomable vastness of \textsf{NP}. Fortunately, this initial impression proved wrong. We know of many \textsf{NP}-hard and \textsf{NP}-complete problems. The first problem to be proven \textsf{NP}-complete is the problem \textsf{SAT} we invoked in Example~\ref{ex:sat}. This has beenn done by Stephen Cook and Leonid Levin who proved Theorem~\ref{thm:cook-levin} in 1971. A proof of this theorem is given in~\cite{langages-formels}.

\begin{theorem}[Cook Levin]\ \\
    \label{thm:cook-levin}
    \textsf{SAT} is \textsf{NP}-complete.
\end{theorem}

Now that we have one problem that we know is \textsf{NP}-complete, it becomes significantly easier to prove that a given problem is \textsf{NP}-hard. Using Proposition~\ref{prop:ple-nph}, we can show any problem is \textsf{NP}-hard by reducing a known \textsf{NP}-hard problem to it. This is what we will do in the following example by proving 3-\textsf{SAT} is \textsf{NP}-complete.

\begin{example}\ \\
    \label{ex:3sat-npc}
    An instance of 3-\textsf{SAT} is a conjunction of clauses with at most 3 literals each and is positive iff it is satisfiable. To show that 3-\textsf{SAT} is \textsf{NP}-complete, we will reduce \textsf{SAT} to it. It is technechally necessary to show that \(3-\textsf{SAT}\in\textsf{NP}\) too, but this is easy given that it is a subproblem of \textsf{SAT} which is already known to be in \textsf{NP}. We will therefore focus on proving it \textsf{NP}-hard.

    To reduce \textsf{SAT} to 3-\textsf{SAT}, we must find for every formula \(\varphi\) of boolean logic a formula \(\varphi'\) in 3CNF, such that \(\varphi'\) is satisfiable iff \(\varphi\) is satisfiable.
\end{example}

