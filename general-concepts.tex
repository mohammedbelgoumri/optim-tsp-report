\chapter{General Concepts}


Throughout this document, we will often find ourselevs in need of a method to objectively measure the difficulty of a problem or the efficiency of an algorithm. Fortunately, there exists an entire branch of theoretical computer science that addresses these very questions: \emph{the theory of computational complexity}.
\section{Computational Complexity}

    The theory of computational complexity is ---as stated above--- a branch of computer science that formalizes the intuitive concept of the \emph{difficulty} of a problem. Quite reasonably, this discipline relies on the premise that a problem is as difficult as it is to perform its most efficient solution, or, to use technical terms, to \emph{execute the most efficient algorithm} that solves the problem.

    For historical (and technical) reasons, most of the work in this branch has been done around a special type of problem called \emph{decision problems}. A decision problem is a problem that has a binary answer, that is, given an instance (or an input) of the problem, we compute an answer (or output) that is an element of some preknown set with cardinality 2. The sets \(\{0, 1\}\), \(\{\texttt{false}, \texttt{true}\}\), and \(\{\texttt{no}, \texttt{yes}\}\), are common examples of such a set, the latter of which will be used in the rest of this discussion.

    A decision problem can therefore be defined as the problem of evaluating some \emph{computable}\footnote{The model of computation is not important when defining decision problems, but it becomes so when discussing their complexity. The turing machine is the model we will use throughout this work.} function \(f: E \rightarrow \{0, 1\}\) where \(E\) is some set of inputs\footnote{Rigorously, for it to be the input spave to a turing machine, \(E\) must be equal to \(\Sigma^\ast\) for some alphabet \(\Sigma\). We will ommit this technicality for the sake of convinience.}. These functions can be mapped to decidable subsets of \(E\) by associating every such a set \(A\) with its characteristic function \(\mathbbm{1}_A\). This correspondence is what motivates Definition~\ref{def:decision-problem} of decidable problems.

    \begin{definition}[Decision Problem]\ \\
        \label{def:decision-problem}
        A decision problem is a pair \(X = \langle E, A \rangle\) where \(E\) is a countable set called the \emph{instance space} and \(A \subset E\) is called the set of \emph{positive instances}. We say the problem \(X\) is decidable iff \(A\) is decidable (i.e. if \(\mathbbm{1}_A\) is computable).
    \end{definition}

    The complexity of a decision problem is given by two pieces of information, the first being its time complexity (intuitively, this is the runtime of the \emph{fastest} turing machine deciding the problem), and the second its space complexity (the \emph{minimal} number of distinct visited cells on the tape of turing machine deciding the problem).


    % A minor technical obstacle to the use of computational complexity theory on the \textsf{TSP} is the fact that this theory only considers so-called decision problems. The \textsf{TSP} beeing an optimization problem, is therefore formally speaking out of the scope of this framework.

    % However, this can be metigated by associating a decision problem with the \textsf{TSP} in such a way as to preserve its difficulty. The rest of this section will provide such an association after developing the necessary tools.

    % \subsection{Combinatorial Optimization Problems}

    %     Combinatorial optimization seeks to find an \emph{optimum} with respect to some \emph{objective} in a discrete \emph{space of options}. Therefore, it suffices to define these parameters in order to define a combinatorial optimization problem. Formally speakeing, we give the following definition:

    %     \begin{definition}[Optimization problem]\ \\
    %         A combinatorial optimization problem (or simply, an optimization problem) \(A\) is given by a quadruple \(A \colonequals (S, R, \mu, f)\) where:
    %         \begin{itemize}
    %             \item \(S\) is a finite or countably infinite set called the \emph{instance space} of \(A\).
    %             \item \(\forall x\in S\ R(x)\) is the set of \emph{feasible solutions} for the instance \(x\).
    %             \item \(\forall x\in S, \forall y \in R(x)\ \mu(x, y)\in\reals_+\) is the measure of \(y\).
    %         \end{itemize}
    %     \end{definition}

    %     Using the above definition, \textsf{TSP} can be defined as \(\textsf{TSP} = (S, R, \mu, f)\) with:
    %     \begin{itemize}
    %         \item \(S\) the set of all complete weighted graphs.
    %         \item For \(G\in S\), \(R(G)\) is the set of all hamiltonian cycles in \(G\).
    %         \item For a hamiltonian cycle \(C\) of \(G\), \(\mu(G, C)\) is the length of \(C\).
    %         \item Finally, the problem is to minimize \(\mu(G, C)\).
    %     \end{itemize}


    % \subsection{Decision Problems}

    %     In contrast to optimization problems, which can have a very large if finite space of solutions, an instance of a decision problem has a binary answer. Hence, decision problems are significantly easier to define and analyze from a theoretical point of view. Formally speaking, we define a decision problem as:

    %     \begin{definition}[Decision problem]\ \\
    %         A decision problem \(A\) is given by a pair \(A \colonequals (S, B)\) where:
    %         \begin{itemize}
    %             \item \(S\) is a set called the \emph{instance space} of \(A\).
    %             \item \(B \subset S\) is the set of \emph{positive instances} of \(A\) (that is instances for which the answer is yes).
    %         \end{itemize}
    %     \end{definition}