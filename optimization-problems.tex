\subsection{Optimization Problems and Their Classification}

Despite their ubiquity, decision problems are not always powerful enough to model a given situation. Combinatorial optimization extends them with a much more general class of problems. Instead of finding a binary answer, a combinatorial optimization problem (or simply, an optimization problem) seeks an \emph{optimal} solution in a discrete \emph{space of options}. The optimality of a solution is judged with respect to an \emph{objective function}.

\begin{definition}[Optimization Problem]\ \\
    \label{def:optimization-problem}
    An optimization problem is a quintuplet \(A=\langle X, S, F, \mu, g\rangle\) where
    \begin{enumerate}[label=\emph{(\roman*)}]
        \item \(X\) is a set of \emph{instances},
        \item \(S\) is a set of \emph{solutions},
        \item \(F:X\rightarrow \mathcal{P}(S)\), for \(x\in X\), \(F(x)\) is called the set of feasible solutions of instance \(x\),
        \item \(\mu:\left\{(x, s) \big| x\in X \wedge s\in F(x) \right\} \rightarrow \reals_+\), \(\mu(x, s)\) is called the \emph{measure} of the solution \(s\) to instance \(x\),
        \item \(g\in\{\min, \max\}\) is the \emph{goal} of the problem.
    \end{enumerate}

    The following notation will be used throughout the rest of this document to refer to optimization problems
    \[
       A = \underset{s\in F(x)}{g}\left\{\mu_x(s)\right\}    
    \]
    If \(g =\min\), the problem is called a \emph{minimization problem}, otherwise, it is called a \emph{maximization problem}.

    For an instance \(x\), we define the \emph{objective function} \(\mu_x:F(x) \rightarrow \reals_+, s \mapsto \mu(x, s)\), the \emph{optimum} \(\mathrm{opt}(x)\colonequals g\left\{\mu(x, s)\big|s\in F(x)\right\}\), and the set of \emph{optimal solutions} 
    \(\mu_x^{-1}\left(\left\{\mathrm{opt}(x)\right\}\right)\). Such an instance is said to be \emph{solvable} if \(F(x)\neq\emptyset\).

    By \emph{solving} \(A\), we mean finding a computable function \(f:X\rightarrow S\) (also called a solver) such that for every solvable \(x\in X\), \(f(x)\in F(x)\). If \(f\) has the additional property that for every solvable \(x\in X\), \(f(x)\) is an optimal solution to \(x\), we say that \(f\) is an \emph{exact} solver of \(A\).
\end{definition}


To understand further clarify Definition~\ref{def:optimization-problem}, we will consider a few examples of optimization problems.

\begin{example}\ \\
    \textsf{LP} or Linear Programming is the problem defined by:
        \begin{itemize}
            \item \textbf{The instance space}: An instance is a triplet \((A, b, c)\) where \(b, c\in\reals^n\), and \(A\in\mathcal{M}_n(\reals)\) for some \(n\in\mathbb{N}\).
            \item \textbf{The solution space}: A solution is a vector \(x\in\reals_+^n\).
            \item \textbf{Feasible solutions (constraints)}: A solution \(x\) is feasible iff \(Ax\le b\).\footnote{Inequality is taken componentwise.}
            \item \textbf{Objective function}: \(\mu_{A,b,c}(x)={}^tcx\).
            \item \textbf{Goal}: \textsf{LP} can be either a maximization or a minimization problem.
        \end{itemize}
        The maximization variant of \textsf{LP} can then be denoted by
        \[\max\limits_{Ax\le b}\left\{^tcx\right\}\]
        Or
        \begin{align*}
            \max{\ {}^tcx}\\
            \mathrm{where\ } Ax \le b
        \end{align*}

    \end{example}
    To every optimization problem \(A\), we can associate a decision problem \(B\). An instance of \(B\) is a pair \(\langle x, m\rangle\), and is positive iff \(\mathrm{opt}(x)=m\). In this fashion we can use the complexity classes of decision problems to define analogues for optimization problems.

    \begin{definition}[NPO]\ \\
        An optimization problem \(A\) is in \classNPO{} (NP optimization) iff the decision problem associated to \(A\) is in \classNP.
    \end{definition}

    It stands the reason that the problems in \classNPO{} can also be divided on the basis of whether their decision variants are \classNP-complete, this is however not a very fruitful classification. 
    
    Instead, we classify \classNPO{} problems based on the difficulty of approximating them (since they can't be easily solved under the hypothesis \(\classNP\neq\classP\)). The very bottom of this hierarchy are problems with decision variants in \classP.

    Immediately above, we find problems that can be approximated to an arbitrary precision in polynomial time, this is captured by Definition~\ref{def:ptas}.

    \begin{definition}[PTAS]\ \\
        \label{def:ptas}
        A Polynomial Time Approximation Scheme (PTAS) for an optimization problem \(A=\langle X, S, F, \mu, g\rangle\) is a computable function \(f:X\times \reals_+ \rightarrow S\) such that
        \[\forall\varepsilon>0, \forall x\in X, \left|\frac{\mathrm{opt}(x) - \mu_x(f(x,\varepsilon))}{\mathrm{opt}(x)}\right| < \varepsilon\]
        and whose runtime is polynomial in the size of the instance.
    \end{definition}

    An example of an \classNPO{} problem (and one whose decision variant is \classNP-complete in fact) who has a PTAS is \textsf{KNAPSACK}. Immediately above PTAS problems, we find problems who can be approximated to some minimum (but not arbitrary) degree of precision. 
    \newcommand{\classAPX}{\textsf{APX}}
    \begin{definition}[APX]\ \\
        \label{def:apx}
        An optimization problem is \classAPX{} iff it has a constant-factor approximation algorithm i.e. a solver \(f\) with the propriety
        \[\exists r>1, \forall x\in X, f(x) \le r\cdot \mathrm{opt}(x) \]

        A problem is \classAPX-complete iff all \classAPX{} problems are PTAS-reducible to it.
    \end{definition}

    It is clear that All PTAS problems are \classAPX{}, but the opposite inclusion is equivalent to \(\classP = \classNP\). Similarly, a problem is \classNPO-complete iff all of \classNPO{} is PTAS-reducible to it.

